{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahs/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "from visualize import draw_dot\n",
    "import requests\n",
    "from nn import Embedding\n",
    "from nn import Linear, Model\n",
    "from optimize import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimize import SGD, Momentum\n",
    "\n",
    "\n",
    "l1 = Linear(1, 5, activation='Relu', bn=True)\n",
    "l2 = Linear(5, 1)\n",
    "batch_size=2\n",
    "\n",
    "model = Model([l1, l2])\n",
    "optim = SGD(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(0, 10000000, 1000)\n",
    "Y = 2*X**2\n",
    "\n",
    "X_norm = (X - np.mean(X)) / np.std(X)\n",
    "Y_norm = (Y - np.mean(Y)) / np.std(Y)\n",
    "\n",
    "X_norm = X_norm.astype(np.float32)\n",
    "Y_norm = Y_norm.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([name:  data: -0.0, grad: 0, op: ÷,\n",
      "       name:  data: -1.0, grad: 0, op: ÷,\n",
      "       name:  data: -0.0, grad: 0, op: ÷,\n",
      "       name:  data: -0.9999998807907104, grad: 0, op: ÷,\n",
      "       name:  data: -0.9999999403953552, grad: 0, op: ÷], dtype=object), array([name:  data: -0.0, grad: 0, op: ÷,\n",
      "       name:  data: 1.0, grad: 0, op: ÷,\n",
      "       name:  data: -0.0, grad: 0, op: ÷,\n",
      "       name:  data: 1.0, grad: 0, op: ÷,\n",
      "       name:  data: 0.9999999403953552, grad: 0, op: ÷], dtype=object)], [name:  data: 0.0, grad: 0, op: , name:  data: 0.0, grad: 0, op: ]]\n"
     ]
    }
   ],
   "source": [
    "ix = np.random.randint(0, X_norm.shape[0], (batch_size,)).flatten()\n",
    "\n",
    "out = model(X_norm[ix])\n",
    "\n",
    "avg_out = sum(out) / len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.007276929449290037: 100%|██████████| 1000/1000 [00:46<00:00, 21.31it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in (t:=trange(1000)):\n",
    "    ix = np.random.randint(0, X_norm.shape[0], (batch_size,)).flatten()\n",
    "\n",
    "    out = model(X_norm[ix])\n",
    "    \n",
    "    optim.zero_grad()\n",
    "\n",
    "    if (batch_size > 1):\n",
    "        batch_loss = sum([((val-Y_norm[ix][i])**2)/batch_size for i, val in enumerate(out)])\n",
    "        batch_loss.backward()\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        loss = (out-Y_norm[ix][0])**2\n",
    "        loss.backward()\n",
    "\n",
    "    optim.step()\n",
    "\n",
    "    t.set_description(f'loss: {batch_loss.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from star2onnx import export_to_onnx\n",
    "\n",
    "\n",
    "onnx_model = export_to_onnx(model.input_shape, model.output_shape, model)\n",
    "onnx.checker.check_model(onnx_model, True)\n",
    "onnx.save(onnx_model, 'model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx2pytorch\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load('model.onnx')\n",
    "\n",
    "pytorch_model = onnx2pytorch.ConvertModel(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = open('datasets/names.txt', 'r').read().splitlines()\n",
    "random.shuffle(names)\n",
    "content_len = 4\n",
    "feature_count = 15\n",
    "w_size = 150\n",
    "\n",
    "chars = sorted(set('.'.join(names)))\n",
    "\n",
    "itos = {i: c for i, c in enumerate(chars)}\n",
    "stoi = {c: i for i, c in enumerate(chars)}\n",
    "\n",
    "def build_dataset(names):\n",
    "    X, Y = [], []\n",
    "    context = [0] * content_len\n",
    "    for name in names:\n",
    "        name += '.'\n",
    "        for c in name:\n",
    "            X.append(context)\n",
    "            Y.append(stoi[c])\n",
    "            context = context[1:] + [stoi[c]]\n",
    "    \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimize import Momentum\n",
    "\n",
    "\n",
    "Xtrain, Ytrain = build_dataset(names)\n",
    "\n",
    "C = Embedding(27, feature_count)\n",
    "l1 = Linear(content_len * feature_count, w_size, activation='Tanh')\n",
    "l2 = Linear(w_size, 27)\n",
    "\n",
    "model = Model([C, l1, l2])\n",
    "\n",
    "optim = Adam(model=model)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Long and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m (t\u001b[38;5;241m:=\u001b[39mtrange(\u001b[38;5;241m100\u001b[39m)):   \n\u001b[1;32m      2\u001b[0m     ix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, Xtrain\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;241m1\u001b[39m,))\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m----> 4\u001b[0m     out_pytorch \u001b[38;5;241m=\u001b[39m \u001b[43mpytorch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     torch_int \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(out_pytorch, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m      7\u001b[0m     out_star \u001b[38;5;241m=\u001b[39m model(Xtrain[ix])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/onnx2pytorch/convert/model.py:224\u001b[0m, in \u001b[0;36mConvertModel.forward\u001b[0;34m(self, *input_list, **input_dict)\u001b[0m\n\u001b[1;32m    222\u001b[0m         activations[out_op_id] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m     activations[out_op_id] \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_activations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# Remove activations that are no longer needed\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m in_op_id \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39minput:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Long and Float"
     ]
    }
   ],
   "source": [
    "for _ in (t:=trange(100)):   \n",
    "    ix = np.random.randint(0, Xtrain.shape[0], (1,)).flatten()\n",
    "\n",
    "    out_pytorch = pytorch_model(torch.tensor(Xtrain[ix]))\n",
    "    torch_int = F.softmax(out_pytorch, dim=1).argmax(dim=1).item()\n",
    "\n",
    "    out_star = model(Xtrain[ix])\n",
    "\n",
    "    maxVal = max([num.data for num in out_star])\n",
    "    exp = [(math.e**(num-maxVal)) for num in out_star]\n",
    "    count = sum([num.data for num in exp])\n",
    "    prob = [val.data/count for val in exp]\n",
    "    star_int = prob.index(max(prob))\n",
    "\n",
    "    if (torch_int != star_int):\n",
    "        raise Exception(f'error! Not equal! torch: {torch_int}, star: {star_int}')\n",
    "\n",
    "    t.set_description(f'torch: {itos[torch_int]}, star: {itos[star_int]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "arr = [1, 2, 3, 4, 5, 6]\n",
    "j=0\n",
    "for i in range(1):\n",
    "    for k in range(len(arr[(j):])):\n",
    "        if k == 1:\n",
    "            j = 50\n",
    "        print(arr[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.195291519165039:   6%|▌         | 588/10000 [2:02:06<32:34:32, 12.46s/it]    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m (t\u001b[38;5;241m:=\u001b[39mtrange(\u001b[38;5;241m10000\u001b[39m)):\n\u001b[1;32m      5\u001b[0m     ix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, Xtrain\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], (batch_size,))\n\u001b[0;32m----> 7\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(out[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m==\u001b[39m Value:\n\u001b[1;32m     10\u001b[0m         out \u001b[38;5;241m=\u001b[39m [out]\n",
      "File \u001b[0;32m~/Desktop/ai/nn.py:56\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, ix)\u001b[0m\n\u001b[1;32m     54\u001b[0m     x \u001b[38;5;241m=\u001b[39m [ixVal]\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 56\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     res\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m res\n",
      "File \u001b[0;32m~/Desktop/ai/nn.py:104\u001b[0m, in \u001b[0;36mLinear.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 104\u001b[0m     out \u001b[38;5;241m=\u001b[39m [neuron(x)\u001b[38;5;241m.\u001b[39mtanh() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTanh\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m neuron(x)\u001b[38;5;241m.\u001b[39mrelu() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m neuron(x) \u001b[38;5;28;01mfor\u001b[39;00m neuron \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneurons]\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/ai/nn.py:104\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 104\u001b[0m     out \u001b[38;5;241m=\u001b[39m [neuron(x)\u001b[38;5;241m.\u001b[39mtanh() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTanh\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m neuron(x)\u001b[38;5;241m.\u001b[39mrelu() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mneuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m neuron \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneurons]\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/ai/nn.py:26\u001b[0m, in \u001b[0;36mNeuron.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 26\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/ai/value.py:21\u001b[0m, in \u001b[0;36mValue.__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m     20\u001b[0m     other \u001b[38;5;241m=\u001b[39m other \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Value) \u001b[38;5;28;01melse\u001b[39;00m Value(other)\n\u001b[0;32m---> 21\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchildren\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backward\u001b[39m():\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m out\u001b[38;5;241m.\u001b[39mgrad\n",
      "File \u001b[0;32m~/Desktop/ai/value.py:5\u001b[0m, in \u001b[0;36mValue.__init__\u001b[0;34m(self, data, children, _backward, _op, name)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mValue\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, children\u001b[38;5;241m=\u001b[39m[], _backward\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m, _op\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32(data)\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren \u001b[38;5;241m=\u001b[39m children\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from value import Value\n",
    "\n",
    "\n",
    "for _ in (t:=trange(10000)):\n",
    "    ix = np.random.randint(0, Xtrain.shape[0], (batch_size,))\n",
    "\n",
    "    out = model(Xtrain[ix])\n",
    "\n",
    "    if type(out[0]) == Value:\n",
    "        out = [out]\n",
    "\n",
    "    expected = Ytrain[ix]\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i, o in enumerate(out):\n",
    "        maxVal = max([num.data for num in o])\n",
    "\n",
    "        exp = [(math.e**(num-maxVal)) for num in o]\n",
    "\n",
    "        count = sum([num for num in exp])\n",
    "\n",
    "        prob = [val/count for val in exp]\n",
    "\n",
    "        loss = prob[int(Ytrain[ix][i])].log()*-1\n",
    "\n",
    "        losses.append(loss)\n",
    "    \n",
    "    batch_loss = sum(losses)/batch_size\n",
    "\n",
    "    optim.zero_grad()\n",
    "\n",
    "    batch_loss.backward()\n",
    "\n",
    "    optim.step()\n",
    "    \n",
    "    t.set_description(f'loss: {batch_loss.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.84206177242871\n"
     ]
    }
   ],
   "source": [
    "avg_loss = 0\n",
    "countt = 0\n",
    "random.shuffle(names)\n",
    "for name in names[:10]:\n",
    "    context = [0] * content_len\n",
    "    for ch in name:\n",
    "\n",
    "        out = model([context])\n",
    "\n",
    "        maxVal = max([num.data for num in out])\n",
    "\n",
    "        exp = [(2**(num-maxVal)) for num in out]\n",
    "\n",
    "        count = sum([num.data for num in exp])\n",
    "\n",
    "        prob = [val/count for val in exp]\n",
    "\n",
    "        loss = prob[stoi[ch]].log()*-1\n",
    "\n",
    "        context = context[1:] + [stoi[ch]]\n",
    "\n",
    "        avg_loss += loss.data\n",
    "        countt += 1\n",
    "\n",
    "print(f'loss: {avg_loss/countt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ziy.\n",
      "brusmimaiuez.\n",
      "umanh.\n",
      "maytay.\n",
      "karrdal.\n",
      "kell.\n",
      "beaky.\n",
      "majbisyu.\n",
      "bryh.\n",
      "zibeerthi.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    name = ''\n",
    "    context = [0] * content_len\n",
    "    while True:\n",
    "        out = model([context])\n",
    "        maxVal = max([num.data for num in out])\n",
    "        exp = [(math.e**(num-maxVal)) for num in out]\n",
    "        count = sum([num.data for num in exp])\n",
    "        prob = [val.data/count for val in exp]\n",
    "        ix = np.random.choice(len(prob), p=prob)\n",
    "        name += itos[ix]\n",
    "        context = context[1:] + [ix]\n",
    "        if name[-1] == '.':\n",
    "            print(name)\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
