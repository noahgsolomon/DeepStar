{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n",
      "32\n",
      "torch.Size([6, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1962, -0.0137,  0.0802,  0.1040,  2.0837, -0.7427,  0.3677,  0.1969,\n",
       "         -0.2545,  0.0431,  1.0508, -0.6777,  0.3638,  0.6251,  1.1940, -0.5760,\n",
       "          1.1642,  0.6589, -1.4920,  1.9627,  0.1864, -0.2340,  0.0910,  1.8666,\n",
       "         -0.2770, -0.3657, -1.0958,  1.3936, -0.0818,  0.8016,  1.1561, -1.2809],\n",
       "        [-1.7694,  1.0676, -0.1075,  0.2333, -0.8929, -0.4410,  0.0763, -0.0733,\n",
       "          0.9464,  0.9393,  0.7507, -1.4495, -0.5691,  0.5397,  1.3439,  0.0095,\n",
       "         -1.2647, -1.6720,  1.5544, -1.4235,  1.7336, -1.2097, -0.8614, -0.4005,\n",
       "          0.9290, -0.3606, -0.3328, -0.8599, -0.8436,  0.4122, -1.0227,  0.1592],\n",
       "        [-0.7621,  0.3943,  0.4253,  1.9987,  0.6538, -1.2100, -0.4145,  0.6854,\n",
       "          0.3204,  0.0754,  1.7583,  0.1327, -2.4148, -0.5442, -1.1585, -0.9592,\n",
       "         -1.5059,  0.7428,  1.6771,  0.8391, -1.0323,  0.5918, -0.7519, -0.1122,\n",
       "         -2.0282,  0.4637,  0.9534, -0.5927,  0.1276,  1.4806,  0.1294, -0.1742],\n",
       "        [-0.2692, -1.0386,  0.3802,  0.2031, -0.5484,  0.2045, -0.3305, -0.2787,\n",
       "         -0.1183, -1.7528,  0.6530, -0.4070, -0.5769, -0.0334,  0.5927,  1.3738,\n",
       "         -0.2676, -1.1847, -0.6532,  0.3196,  1.4411,  0.6200,  0.6350,  0.3204,\n",
       "          0.2161,  0.4530, -0.4350, -0.9214, -1.4593,  0.4406,  2.0583,  0.2314],\n",
       "        [-0.5115,  0.3098,  1.0493,  0.4641, -1.1926,  0.3472, -1.1111, -0.1105,\n",
       "          0.3295,  0.6512, -0.7617, -0.0171,  0.4833, -0.0187, -0.0909,  0.0876,\n",
       "         -0.8016, -0.7409,  1.1472,  1.4231,  1.4991,  0.8108,  2.3699, -0.3953,\n",
       "          0.5241, -0.1920, -1.1105,  1.7490,  0.8051, -1.0996,  0.0623,  0.3482],\n",
       "        [-0.6796,  0.4842,  0.3287,  1.2805, -2.0616, -1.0598,  0.8985, -1.4984,\n",
       "         -1.1484,  1.1747,  0.8266,  0.7859,  0.4479,  0.9402, -1.1197, -1.3604,\n",
       "         -0.7020, -0.6027,  1.2979,  0.5349, -0.0206, -0.9796, -0.7639,  0.0083,\n",
       "          0.6157, -1.2694,  0.6452, -0.0232,  0.0721,  0.5783,  0.6505,  0.6193]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BobNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoding = tiktoken.get_encoding(\"r50k_base\")\n",
    "        self.emb_size = self.encoding.n_vocab\n",
    "        self.emb_channels = 32\n",
    "\n",
    "        print(self.emb_size)\n",
    "        print(self.emb_channels)\n",
    "\n",
    "        self.emb = nn.Embedding(self.emb_size, self.emb_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoding.encode(x)\n",
    "        x = self.emb(torch.tensor(x))\n",
    "        return x\n",
    "    \n",
    "\n",
    "sup = BobNet()\n",
    "sup('tiktoken is goated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
