{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import tiktoken\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + 1e-6) + self.beta\n",
    "\n",
    "class BobNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoding = tiktoken.get_encoding(\"r50k_base\")\n",
    "        self.emb_size = self.encoding.n_vocab\n",
    "        self.emb_channels = 32\n",
    "        self.emb = nn.Embedding(self.emb_size, self.emb_channels)\n",
    "        self.qW = torch.randn(self.emb_channels, self.emb_channels)\n",
    "        self.kW = torch.randn(self.emb_channels, self.emb_channels)\n",
    "        self.vW = torch.randn(self.emb_channels, self.emb_channels)\n",
    "        self.oW = torch.randn(self.emb_channels, self.emb_channels)\n",
    "        self.gamma = torch.randn(self.emb_channels)\n",
    "        self.beta = torch.randn(self.emb_channels)\n",
    "        self.num_heads = 8\n",
    "        self.head_dim = self.emb_channels // self.num_heads\n",
    "        assert self.head_dim * self.num_heads == self.emb_channels, \"emb_channels must be divisible by num_heads\"\n",
    "        self.l1 = nn.Linear(self.emb_channels, 250)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(250, self.emb_size)\n",
    "        self.ln1 = LayerNorm(self.emb_channels)\n",
    "        self.ln2 = LayerNorm(self.emb_size)\n",
    "\n",
    "\n",
    "    def positional_encoding(self, x):\n",
    "        _, seq_length, d = x.shape\n",
    "        encoding = x.clone()\n",
    "        pos = torch.arange(seq_length).unsqueeze(1)\n",
    "        i = torch.arange(d).unsqueeze(0)\n",
    "        factor = 10000 ** (2 * i / d)\n",
    "        position_tensor = pos / factor\n",
    "        for i in i[0]:\n",
    "            encoding += torch.sin(position_tensor) if i % 2 == 0 else torch.cos(position_tensor)\n",
    "        return encoding\n",
    "    \n",
    "    def split_heads(self, x, batch_size):\n",
    "        return x.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "    def self_attention(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        # dim: (batch_size, num_heads, seq_length, head_dim)\n",
    "        q = self.split_heads(x @ self.qW, batch_size)\n",
    "        k = self.split_heads(x @ self.kW, batch_size)\n",
    "        v = self.split_heads(x @ self.vW, batch_size)\n",
    "        qK = (q @ k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        qK = self.mask(qK)\n",
    "        attention_weights = F.softmax(qK, dim=-1)\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.emb_channels)\n",
    "        output = output @ self.oW\n",
    "        output += x\n",
    "        return output\n",
    "        \n",
    "    def mask(self, x):\n",
    "        seq_length = x.shape[2]\n",
    "        mask = torch.tril(torch.ones((seq_length, seq_length), device=x.device))\n",
    "        mask = mask.unsqueeze(0).unsqueeze(1)\n",
    "        mask = mask.repeat(x.shape[0], self.num_heads, 1, 1)\n",
    "        return x.masked_fill(mask == 0, float('-inf'))\n",
    "    \n",
    "    def feed_forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        max_length = max(t.size(0) for t in x)\n",
    "        padded = [F.pad(t, (0, max_length - t.size(0))) for t in x]\n",
    "        input_tensor = torch.stack(padded)\n",
    "        x = self.emb(input_tensor)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ln1(x)\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ln1(x)\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ln1(x)\n",
    "        x = self.feed_forward(x)\n",
    "        x = self.ln2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train has 301,966 tokens\n",
      "val has 36,059 tokens\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "\n",
    "# download the tiny shakespeare dataset\n",
    "input_file_path = os.path.join('', 'input.txt')\n",
    "if not os.path.exists(input_file_path):\n",
    "    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "    with open(input_file_path, 'w') as f:\n",
    "        f.write(requests.get(data_url).text)\n",
    "\n",
    "with open(input_file_path, 'r') as f:\n",
    "    data = f.read()\n",
    "n = len(data)\n",
    "train_data = data[:int(n*0.9)]\n",
    "val_data = data[int(n*0.9):]\n",
    "\n",
    "# encode with tiktoken gpt2 bpe\n",
    "enc = tiktoken.get_encoding(\"r50k_base\")\n",
    "train_ids = enc.encode_ordinary(train_data)\n",
    "val_ids = enc.encode_ordinary(val_data)\n",
    "print(f\"train has {len(train_ids):,} tokens\")\n",
    "print(f\"val has {len(val_ids):,} tokens\")\n",
    "\n",
    "# export to bin files\n",
    "train_ids = np.array(train_ids, dtype=np.int32)\n",
    "val_ids = np.array(val_ids, dtype=np.int32)\n",
    "train_ids.tofile(os.path.join('', 'train.bin'))\n",
    "val_ids.tofile(os.path.join('', 'val.bin'))\n",
    "\n",
    "# train.bin has 301,966 tokens\n",
    "# val.bin has 36,059 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, file_path, seq_length):\n",
    "        self.file_path = file_path\n",
    "        self.seq_length = seq_length\n",
    "        self.data = np.memmap(file_path, dtype=np.int32, mode='r')\n",
    "        self.num_samples = len(self.data) // seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_index = idx * self.seq_length\n",
    "        end_index = start_index + self.seq_length + 1  # +1 for target\n",
    "        sequence = self.data[start_index:end_index]\n",
    "        input_seq = torch.tensor(sequence[:-1], dtype=torch.long)\n",
    "        target_seq = torch.tensor(sequence[1:], dtype=torch.long)\n",
    "        return input_seq, target_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BobNet(\n",
       "  (emb): Embedding(50257, 32)\n",
       "  (l1): Linear(in_features=32, out_features=250, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (l2): Linear(in_features=250, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Parameters\n",
    "seq_length = 100\n",
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset = TokenDataset('train.bin', seq_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model, Loss Function, Optimizer\n",
    "model = BobNet()\n",
    "crossentropy = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 11.406697273254395, count: 1:   0%|          | 0/1 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 11.028656005859375, count: 2:   0%|          | 0/1 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 10.685254096984863, count: 3:   0%|          | 0/1 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 10.295941352844238, count: 4:   0%|          | 0/1 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 9.877725601196289, count: 5:   0%|          | 0/1 [00:04<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 9.499773025512695, count: 6:   0%|          | 0/1 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 9.09717082977295, count: 7:   0%|          | 0/1 [00:05<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.589666366577148, count: 8:   0%|          | 0/1 [00:06<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.147370338439941, count: 9:   0%|          | 0/1 [00:07<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.665311336517334, count: 10:   0%|          | 0/1 [00:07<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.565147876739502, count: 11:   0%|          | 0/1 [00:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.442837715148926, count: 12:   0%|          | 0/1 [00:09<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.130145072937012, count: 13:   0%|          | 0/1 [00:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.004541873931885, count: 14:   0%|          | 0/1 [00:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.927102565765381, count: 15:   0%|          | 0/1 [00:11<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.041494369506836, count: 16:   0%|          | 0/1 [00:12<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.268843173980713, count: 17:   0%|          | 0/1 [00:13<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.777126312255859, count: 18:   0%|          | 0/1 [00:13<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.650027275085449, count: 19:   0%|          | 0/1 [00:14<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.943488121032715, count: 20:   0%|          | 0/1 [00:15<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.712258338928223, count: 21:   0%|          | 0/1 [00:16<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.892702579498291, count: 22:   0%|          | 0/1 [00:17<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.5770416259765625, count: 23:   0%|          | 0/1 [00:18<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.759511947631836, count: 24:   0%|          | 0/1 [00:19<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.820306301116943, count: 25:   0%|          | 0/1 [00:20<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.955920219421387, count: 26:   0%|          | 0/1 [00:21<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.959603786468506, count: 27:   0%|          | 0/1 [00:22<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.6196513175964355, count: 28:   0%|          | 0/1 [00:23<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.603310585021973, count: 29:   0%|          | 0/1 [00:23<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.741826057434082, count: 30:   0%|          | 0/1 [00:24<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.7150115966796875, count: 31:   0%|          | 0/1 [00:25<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.7114996910095215, count: 32:   0%|          | 0/1 [00:25<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.57071590423584, count: 33:   0%|          | 0/1 [00:26<?, ?it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.601880073547363, count: 34:   0%|          | 0/1 [00:26<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.7456464767456055, count: 35:   0%|          | 0/1 [00:27<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.425410747528076, count: 36:   0%|          | 0/1 [00:27<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.5716962814331055, count: 37:   0%|          | 0/1 [00:29<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.731622219085693, count: 38:   0%|          | 0/1 [00:30<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.484989643096924, count: 39:   0%|          | 0/1 [00:30<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.565017223358154, count: 40:   0%|          | 0/1 [00:31<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.31174898147583, count: 41:   0%|          | 0/1 [00:32<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.471832752227783, count: 42:   0%|          | 0/1 [00:33<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.598252296447754, count: 43:   0%|          | 0/1 [00:33<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.528338432312012, count: 44:   0%|          | 0/1 [00:34<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.644890308380127, count: 45:   0%|          | 0/1 [00:34<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.721464157104492, count: 46:   0%|          | 0/1 [00:35<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.637088298797607, count: 47:   0%|          | 0/1 [00:35<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.726498603820801, count: 48:   0%|          | 0/1 [00:36<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.637736797332764, count: 49:   0%|          | 0/1 [00:37<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.572756290435791, count: 50:   0%|          | 0/1 [00:37<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.521609783172607, count: 51:   0%|          | 0/1 [00:38<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.524171829223633, count: 52:   0%|          | 0/1 [00:38<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.592225074768066, count: 53:   0%|          | 0/1 [00:39<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.5459818840026855, count: 54:   0%|          | 0/1 [00:39<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.445036888122559, count: 55:   0%|          | 0/1 [00:40<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.494716644287109, count: 56:   0%|          | 0/1 [00:41<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.6726531982421875, count: 57:   0%|          | 0/1 [00:42<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.431987762451172, count: 58:   0%|          | 0/1 [00:42<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.4583563804626465, count: 59:   0%|          | 0/1 [00:43<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.568286895751953, count: 60:   0%|          | 0/1 [00:43<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.614152431488037, count: 61:   0%|          | 0/1 [00:44<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.456968784332275, count: 62:   0%|          | 0/1 [00:44<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.449178695678711, count: 63:   0%|          | 0/1 [00:45<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.53750467300415, count: 64:   0%|          | 0/1 [00:46<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.746164321899414, count: 65:   0%|          | 0/1 [00:46<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.486577987670898, count: 66:   0%|          | 0/1 [00:47<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.531425476074219, count: 67:   0%|          | 0/1 [00:47<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.683353900909424, count: 68:   0%|          | 0/1 [00:48<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.591375350952148, count: 69:   0%|          | 0/1 [00:48<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.787597179412842, count: 70:   0%|          | 0/1 [00:49<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.7312912940979, count: 71:   0%|          | 0/1 [00:49<?, ?it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.424096584320068, count: 72:   0%|          | 0/1 [00:50<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.536646842956543, count: 73:   0%|          | 0/1 [00:51<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.444067001342773, count: 74:   0%|          | 0/1 [00:51<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.550556659698486, count: 75:   0%|          | 0/1 [00:52<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.456536293029785, count: 76:   0%|          | 0/1 [00:52<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.3978352546691895, count: 77:   0%|          | 0/1 [00:53<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.36771297454834, count: 78:   0%|          | 0/1 [00:53<?, ?it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.3849921226501465, count: 79:   0%|          | 0/1 [00:54<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.464901447296143, count: 80:   0%|          | 0/1 [00:55<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.342888832092285, count: 81:   0%|          | 0/1 [00:56<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.270084381103516, count: 82:   0%|          | 0/1 [00:56<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.561153888702393, count: 83:   0%|          | 0/1 [00:57<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.516836166381836, count: 84:   0%|          | 0/1 [00:58<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.496030807495117, count: 85:   0%|          | 0/1 [00:59<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.37546443939209, count: 86:   0%|          | 0/1 [01:00<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.593649864196777, count: 87:   0%|          | 0/1 [01:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.675014019012451, count: 88:   0%|          | 0/1 [01:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.628148555755615, count: 89:   0%|          | 0/1 [01:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.400125503540039, count: 90:   0%|          | 0/1 [01:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.474215030670166, count: 91:   0%|          | 0/1 [01:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.607260227203369, count: 92:   0%|          | 0/1 [01:06<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.159016132354736, count: 93:   0%|          | 0/1 [01:06<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.492709636688232, count: 94:   0%|          | 0/1 [01:07<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.674578666687012, count: 95:   0%|          | 0/1 [01:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.467649936676025, count: 96:   0%|          | 0/1 [01:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.371585845947266, count: 97:   0%|          | 0/1 [01:09<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.374120712280273, count: 98:   0%|          | 0/1 [01:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.34811544418335, count: 99:   0%|          | 0/1 [01:11<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.592215538024902, count: 100:   0%|          | 0/1 [01:11<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.463155746459961, count: 101:   0%|          | 0/1 [01:12<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.476869583129883, count: 102:   0%|          | 0/1 [01:12<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.380344867706299, count: 103:   0%|          | 0/1 [01:14<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.56675910949707, count: 104:   0%|          | 0/1 [01:15<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.580817222595215, count: 105:   0%|          | 0/1 [01:16<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.360342025756836, count: 106:   0%|          | 0/1 [01:16<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 50257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 6.360342025756836, count: 106:   0%|          | 0/1 [01:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "num_epochs = 5  # Number of epochs\n",
    "\n",
    "for epoch in (t:=trange(1)):\n",
    "    count = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.view(-1, outputs.size(-1))\n",
    "        loss = crossentropy(outputs, targets.view(-1))\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        t.set_description(f'loss: {loss.item()}, count: {count}')\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and this is lord toWhere:; faire to time, with William\n",
      " senate for MAR\n",
      "FR. dear: hence, said IedID dagger we forth overU on, thr make manners with A me taste\n",
      " shall husband my, of the\n",
      "\n",
      "\n",
      " breathsBut God he dispos cr, kn majesty Tar is came\n",
      " falsebuttonared moral cutThe'll\n",
      "'y lend stillhornWhetherAff thyGod gracious prince soldiers dead good? deeds seldom, hadGRPET Rome with\n",
      "\n",
      "\n",
      ". three sorrow:ES,A fair,ost the..\n",
      " twoative not a grave his OButLarpt sir holyC sir:US King\n",
      "\n",
      ",'d\n",
      "Esc and lend will reap LA contentionPR tr pays seasORT gravity\n",
      ", may hathace fathersYC\n",
      " withpt cityOL,ight toThough noUS and crept spider hateful isUEits\n",
      ",For Tower\n",
      "INGS Warwick\n",
      " thisQ\n",
      "audio as Rome\n",
      "erers,:,ceral by cause reasonswithland\n",
      ",orsetoth\n",
      "\n",
      "IO despair sorrow,\n",
      " a like sonBoy slave.,I itbyiment\n",
      "oughOr\n",
      "To\n",
      "On BrotherWARDC\n",
      " to Tromed hath comeF thee, unt, march death andshs drumWhat my right,G: the\n",
      "oth\n",
      " true, after, I have\n",
      "ham so:ThatOP ' Brittany;.CORock,None forth he\n",
      " myGood,; nine dinner; peace such spUR knock\n",
      " hourlyURAndAU\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "input_text = \"hey\"\n",
    "\n",
    "input_ids = model.encoding.encode(input_text)\n",
    "\n",
    "# Number of tokens to generate\n",
    "num_tokens_to_generate = 300\n",
    "\n",
    "# Convert to a tensor and add batch dimension (unsqueeze(0) adds a batch dimension)\n",
    "input_tensor = torch.tensor(input_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "# Generate tokens\n",
    "generated_tokens = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_tokens_to_generate):\n",
    "        # Get the model's prediction for the next token\n",
    "        outputs = model(input_tensor)\n",
    "        \n",
    "        # Only get the logits of the last token in the sequence\n",
    "        next_token_logits = outputs[:, -1, :]\n",
    "        \n",
    "        # Sample the next token from the probability distribution (you can also use argmax)\n",
    "        next_token = torch.multinomial(F.softmax(next_token_logits, dim=-1), num_samples=1)\n",
    "        \n",
    "        # Append the predicted token to the list of generated tokens\n",
    "        generated_tokens.append(next_token.item())\n",
    "        \n",
    "        # Append the new token to the input sequence for the next prediction\n",
    "        input_tensor = torch.cat((input_tensor, next_token.unsqueeze(0)[0]), dim=1)\n",
    "\n",
    "# Decode the generated tokens back to text\n",
    "generated_text = enc.decode(generated_tokens)\n",
    "\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
